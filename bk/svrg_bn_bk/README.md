#TODO:
    - Custom updates +
    - Changing learning rate `alpha_k = alpha_0 / (k+1)^t` +
    - Parameters selection +
    - 2D embedding visualization +
    - Layer weights visualization +
    - Denoising autoencoder +
    - Deeper network +
    - Hessian free optimization
    
    - `SAG` and `SVRG` optimization +
    - Classifier on top of deep network +
    - Sparse autoencoder +
    - Try another dataset (like CIFAR-10)

    - Adaptive Lipschitz constant +
    - Proportionate probabilities +
    - Second-order information in SVRG
