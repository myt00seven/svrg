In the code from CIFAR wepage, the dataset is read as:

print(train_x.shape) 	(494021, 41)
print(train_y.shape) 	(494021,)
print(test_x.shape) 	(311029, 41)
print(test_y.shape) 	(311029,)

In the code for MNIST, the dataset is read as:


X_train
(50000, 1, 28, 28)
float32
y_train
(50000,)
X_val
(10000, 1, 28, 28)
y_val
(10000,)
X_test
(10000, 1, 28, 28)
y_test
(10000,)

Todo:
1) read the CIFAR dataset
2) put the origianl alexnet into work
3) modify the original alexnet, change LRN layer to BN layer 

1)
it seems now the CIFAR dataset is read. 

2)
compute the mean_file
the BN use different prediction for training and predicting

I just realized that we can't apply Alexnet to CIFAR. Since the structure of conv layer highly rely on the specifics of the input data. Changing the dimension of data also means change the structure of the cnn network and thus it is no more the same model.

===========================================================================

Ref: http://sachintalathi.com/?p=546

todo:
1) read the CFIAR dataste √
2) run the "naive" CNN model with original BN layer √
3) add data output to output val_loss and val_acc √
4) adjust the drawing python script accordingly √
5) add customized BN layer \ DBN to the model √
5.2) add control for main.py √
6) small scale, all models test (3 epoches) √
7) estimate time and epoches for best result  √
	-	from the obervation of first experiment, the loss_val is decreasing after 20 epochs. So I estimate the full scale will take up to 30-50 epochs to run.
	- so I will suggest 50 epochs for the first runs
8) run all 10 models for full scale experiment √
9) The MNIST and NI dataset is run with sgd instead of adagrad! Need to rerun them as well! √
9.1) store the old results run with sgd √
9.2) rerun MNIST with adagrad and update all the graphs and tables √
9.3) rerun NI with adagrad and update all the graphs and tables √
10) Update the results with adagrad for all three dataset √

11) incorperate the edits √
11.1) edit words √
11.2) regenerate figures √
12) read the whole paper for once √

13) finish incorprating the edits and comments √
13.1) I still have three paragraphs to edit. The first one is going to be harder, and the rest of two is easier. √
14) try to compress into 8 pages (whatever send to diego will include what's changed. Maybe I should delelte the deleted sentences and only leave the new one. So I won't need to compress twice.) I still have half more page. √
15) add a new title for the appendix √
16) check the nips backup pdf and the nips website for format requirement  √
17) send it to Diego √
18) upload to NIPS
19) upload to arxiv
















