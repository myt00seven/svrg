Using gpu device 0: GeForce GTX TITAN Z
/home/jaehyun/github/Lasagne/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.
  warnings.warn("The uniform initializer no longer uses Glorot et al.'s "
/home/jaehyun/github/Lasagne/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.
  warnings.warn("get_all_layers() has been changed to return layers in "
Network Architecture ---------------
input :  (32, 3, 224, 224)
conv1 :  (32, 64, 112, 112)
conv1_bn :  (32, 64, 112, 112)
conv1_relu :  (32, 64, 112, 112)
pool1 :  (32, 64, 56, 56)
conv2_reduce :  (32, 64, 56, 56)
conv2_reduce_bn :  (32, 64, 56, 56)
conv2_reduce_relu :  (32, 64, 56, 56)
conv2 :  (32, 192, 56, 56)
conv2_bn :  (32, 192, 56, 56)
conv2_relu :  (32, 192, 56, 56)
pool2 :  (32, 192, 28, 28)
inception_3a_1x1 :  (32, 64, 28, 28)
inception_3a_1x1_bn :  (32, 64, 28, 28)
inception_3a_1x1_relu :  (32, 64, 28, 28)
inception_3a_3x3_reduce :  (32, 96, 28, 28)
inception_3a_3x3_reduce_bn :  (32, 96, 28, 28)
inception_3a_3x3_reduce_relu :  (32, 96, 28, 28)
inception_3a_3x3 :  (32, 128, 28, 28)
inception_3a_3x3_bn :  (32, 128, 28, 28)
inception_3a_3x3_relu :  (32, 128, 28, 28)
inception_3a_5x5_reduce :  (32, 16, 28, 28)
inception_3a_5x5_reduce_bn :  (32, 16, 28, 28)
inception_3a_5x5_reduce_relu :  (32, 16, 28, 28)
inception_3a_5x5 :  (32, 32, 28, 28)
inception_3a_5x5_bn :  (32, 32, 28, 28)
inception_3a_5x5_relu :  (32, 32, 28, 28)
inception_3a_pool :  (32, 192, 28, 28)
inception_3a_pool_proj :  (32, 32, 28, 28)
inception_3a_pool_proj_bn :  (32, 32, 28, 28)
inception_3a_pool_proj_relu :  (32, 32, 28, 28)
inception_3a_output :  (32, 256, 28, 28)
inception_3b_1x1 :  (32, 128, 28, 28)
inception_3b_1x1_bn :  (32, 128, 28, 28)
inception_3b_1x1_relu :  (32, 128, 28, 28)
inception_3b_3x3_reduce :  (32, 128, 28, 28)
inception_3b_3x3_reduce_bn :  (32, 128, 28, 28)
inception_3b_3x3_reduce_relu :  (32, 128, 28, 28)
inception_3b_3x3 :  (32, 192, 28, 28)
inception_3b_3x3_bn :  (32, 192, 28, 28)
inception_3b_3x3_relu :  (32, 192, 28, 28)
inception_3b_5x5_reduce :  (32, 32, 28, 28)
inception_3b_5x5_reduce_bn :  (32, 32, 28, 28)
inception_3b_5x5_reduce_relu :  (32, 32, 28, 28)
inception_3b_5x5 :  (32, 96, 28, 28)
inception_3b_5x5_bn :  (32, 96, 28, 28)
inception_3b_5x5_relu :  (32, 96, 28, 28)
inception_3b_pool :  (32, 256, 28, 28)
inception_3b_pool_proj :  (32, 64, 28, 28)
inception_3b_pool_proj_bn :  (32, 64, 28, 28)
inception_3b_pool_proj_relu :  (32, 64, 28, 28)
inception_3b_output :  (32, 480, 28, 28)
pool3 :  (32, 480, 14, 14)
inception_4a_1x1 :  (32, 192, 14, 14)
inception_4a_1x1_bn :  (32, 192, 14, 14)
inception_4a_1x1_relu :  (32, 192, 14, 14)
inception_4a_3x3_reduce :  (32, 96, 14, 14)
inception_4a_3x3_reduce_bn :  (32, 96, 14, 14)
inception_4a_3x3_reduce_relu :  (32, 96, 14, 14)
inception_4a_3x3 :  (32, 208, 14, 14)
inception_4a_3x3_bn :  (32, 208, 14, 14)
inception_4a_3x3_relu :  (32, 208, 14, 14)
inception_4a_5x5_reduce :  (32, 16, 14, 14)
inception_4a_5x5_reduce_bn :  (32, 16, 14, 14)
inception_4a_5x5_reduce_relu :  (32, 16, 14, 14)
inception_4a_5x5 :  (32, 48, 14, 14)
inception_4a_5x5_bn :  (32, 48, 14, 14)
inception_4a_5x5_relu :  (32, 48, 14, 14)
inception_4a_pool :  (32, 480, 14, 14)
inception_4a_pool_proj :  (32, 64, 14, 14)
inception_4a_pool_proj_bn :  (32, 64, 14, 14)
inception_4a_pool_proj_relu :  (32, 64, 14, 14)
inception_4a_output :  (32, 512, 14, 14)
loss1_ave_pool :  (32, 512, 4, 4)
loss1_conv :  (32, 128, 4, 4)
loss1_conv_bn :  (32, 128, 4, 4)
loss1_conv_relu :  (32, 128, 4, 4)
loss1_fc :  (32, 1024)
loss1_fc_bn :  (32, 1024)
loss1_fc_relu :  (32, 1024)
loss1_classifier :  (32, 1000)
inception_4b_1x1 :  (32, 160, 14, 14)
inception_4b_1x1_bn :  (32, 160, 14, 14)
inception_4b_1x1_relu :  (32, 160, 14, 14)
inception_4b_3x3_reduce :  (32, 112, 14, 14)
inception_4b_3x3_reduce_bn :  (32, 112, 14, 14)
inception_4b_3x3_reduce_relu :  (32, 112, 14, 14)
inception_4b_3x3 :  (32, 224, 14, 14)
inception_4b_3x3_bn :  (32, 224, 14, 14)
inception_4b_3x3_relu :  (32, 224, 14, 14)
inception_4b_5x5_reduce :  (32, 24, 14, 14)
inception_4b_5x5_reduce_bn :  (32, 24, 14, 14)
inception_4b_5x5_reduce_relu :  (32, 24, 14, 14)
inception_4b_5x5 :  (32, 64, 14, 14)
inception_4b_5x5_bn :  (32, 64, 14, 14)
inception_4b_5x5_relu :  (32, 64, 14, 14)
inception_4b_pool :  (32, 512, 14, 14)
inception_4b_pool_proj :  (32, 64, 14, 14)
inception_4b_pool_proj_bn :  (32, 64, 14, 14)
inception_4b_pool_proj_relu :  (32, 64, 14, 14)
inception_4b_output :  (32, 512, 14, 14)
inception_4c_1x1 :  (32, 128, 14, 14)
inception_4c_1x1_bn :  (32, 128, 14, 14)
inception_4c_1x1_relu :  (32, 128, 14, 14)
inception_4c_3x3_reduce :  (32, 128, 14, 14)
inception_4c_3x3_reduce_bn :  (32, 128, 14, 14)
inception_4c_3x3_reduce_relu :  (32, 128, 14, 14)
inception_4c_3x3 :  (32, 256, 14, 14)
inception_4c_3x3_bn :  (32, 256, 14, 14)
inception_4c_3x3_relu :  (32, 256, 14, 14)
inception_4c_5x5_reduce :  (32, 24, 14, 14)
inception_4c_5x5_reduce_bn :  (32, 24, 14, 14)
inception_4c_5x5_reduce_relu :  (32, 24, 14, 14)
inception_4c_5x5 :  (32, 64, 14, 14)
inception_4c_5x5_bn :  (32, 64, 14, 14)
inception_4c_5x5_relu :  (32, 64, 14, 14)
inception_4c_pool :  (32, 512, 14, 14)
inception_4c_pool_proj :  (32, 64, 14, 14)
inception_4c_pool_proj_bn :  (32, 64, 14, 14)
inception_4c_pool_proj_relu :  (32, 64, 14, 14)
inception_4c_output :  (32, 512, 14, 14)
inception_4d_1x1 :  (32, 128, 14, 14)
inception_4d_1x1_bn :  (32, 128, 14, 14)
inception_4d_1x1_relu :  (32, 128, 14, 14)
inception_4d_3x3_reduce :  (32, 128, 14, 14)
inception_4d_3x3_reduce_bn :  (32, 128, 14, 14)
inception_4d_3x3_reduce_relu :  (32, 128, 14, 14)
inception_4d_3x3 :  (32, 256, 14, 14)
inception_4d_3x3_bn :  (32, 256, 14, 14)
inception_4d_3x3_relu :  (32, 256, 14, 14)
inception_4d_5x5_reduce :  (32, 24, 14, 14)
inception_4d_5x5_reduce_bn :  (32, 24, 14, 14)
inception_4d_5x5_reduce_relu :  (32, 24, 14, 14)
inception_4d_5x5 :  (32, 64, 14, 14)
inception_4d_5x5_bn :  (32, 64, 14, 14)
inception_4d_5x5_relu :  (32, 64, 14, 14)
inception_4d_pool :  (32, 512, 14, 14)
inception_4d_pool_proj :  (32, 64, 14, 14)
inception_4d_pool_proj_bn :  (32, 64, 14, 14)
inception_4d_pool_proj_relu :  (32, 64, 14, 14)
inception_4d_output :  (32, 512, 14, 14)
loss2_ave_pool :  (32, 512, 4, 4)
loss2_conv :  (32, 128, 4, 4)
loss2_conv_bn :  (32, 128, 4, 4)
loss2_conv_relu :  (32, 128, 4, 4)
loss2_fc :  (32, 1024)
loss2_fc_bn :  (32, 1024)
loss2_fc_relu :  (32, 1024)
loss2_classifier :  (32, 1000)
inception_4e_1x1 :  (32, 256, 14, 14)
inception_4e_1x1_bn :  (32, 256, 14, 14)
inception_4e_1x1_relu :  (32, 256, 14, 14)
inception_4e_3x3_reduce :  (32, 160, 14, 14)
inception_4e_3x3_reduce_bn :  (32, 160, 14, 14)
inception_4e_3x3_reduce_relu :  (32, 160, 14, 14)
inception_4e_3x3 :  (32, 320, 14, 14)
inception_4e_3x3_bn :  (32, 320, 14, 14)
inception_4e_3x3_relu :  (32, 320, 14, 14)
inception_4e_5x5_reduce :  (32, 32, 14, 14)
inception_4e_5x5_reduce_bn :  (32, 32, 14, 14)
inception_4e_5x5_reduce_relu :  (32, 32, 14, 14)
inception_4e_5x5 :  (32, 128, 14, 14)
inception_4e_5x5_bn :  (32, 128, 14, 14)
inception_4e_5x5_relu :  (32, 128, 14, 14)
inception_4e_pool :  (32, 512, 14, 14)
inception_4e_pool_proj :  (32, 128, 14, 14)
inception_4e_pool_proj_bn :  (32, 128, 14, 14)
inception_4e_pool_proj_relu :  (32, 128, 14, 14)
inception_4e_output :  (32, 832, 14, 14)
pool4 :  (32, 832, 7, 7)
inception_5a_1x1 :  (32, 256, 7, 7)
inception_5a_1x1_bn :  (32, 256, 7, 7)
inception_5a_1x1_relu :  (32, 256, 7, 7)
inception_5a_3x3_reduce :  (32, 160, 7, 7)
inception_5a_3x3_reduce_bn :  (32, 160, 7, 7)
inception_5a_3x3_reduce_relu :  (32, 160, 7, 7)
inception_5a_3x3 :  (32, 320, 7, 7)
inception_5a_3x3_bn :  (32, 320, 7, 7)
inception_5a_3x3_relu :  (32, 320, 7, 7)
inception_5a_5x5_reduce :  (32, 32, 7, 7)
inception_5a_5x5_reduce_bn :  (32, 32, 7, 7)
inception_5a_5x5_reduce_relu :  (32, 32, 7, 7)
inception_5a_5x5 :  (32, 128, 7, 7)
inception_5a_5x5_bn :  (32, 128, 7, 7)
inception_5a_5x5_relu :  (32, 128, 7, 7)
inception_5a_pool :  (32, 832, 7, 7)
inception_5a_pool_proj :  (32, 128, 7, 7)
inception_5a_pool_proj_bn :  (32, 128, 7, 7)
inception_5a_pool_proj_relu :  (32, 128, 7, 7)
inception_5a_output :  (32, 832, 7, 7)
inception_5b_1x1 :  (32, 384, 7, 7)
inception_5b_1x1_bn :  (32, 384, 7, 7)
inception_5b_1x1_relu :  (32, 384, 7, 7)
inception_5b_3x3_reduce :  (32, 192, 7, 7)
inception_5b_3x3_reduce_bn :  (32, 192, 7, 7)
inception_5b_3x3_reduce_relu :  (32, 192, 7, 7)
inception_5b_3x3 :  (32, 384, 7, 7)
inception_5b_3x3_bn :  (32, 384, 7, 7)
inception_5b_3x3_relu :  (32, 384, 7, 7)
inception_5b_5x5_reduce :  (32, 48, 7, 7)
inception_5b_5x5_reduce_bn :  (32, 48, 7, 7)
inception_5b_5x5_reduce_relu :  (32, 48, 7, 7)
inception_5b_5x5 :  (32, 128, 7, 7)
inception_5b_5x5_bn :  (32, 128, 7, 7)
inception_5b_5x5_relu :  (32, 128, 7, 7)
inception_5b_pool :  (32, 832, 7, 7)
inception_5b_pool_proj :  (32, 128, 7, 7)
inception_5b_pool_proj_bn :  (32, 128, 7, 7)
inception_5b_pool_proj_relu :  (32, 128, 7, 7)
inception_5b_output :  (32, 1024, 7, 7)
pool5 :  (32, 1024, 1, 1)
loss3_classifier :  (32, 1000)
Parameters -------------------------
conv1.W (64, 3, 7, 7)
conv1_bn.gamma (64,)
conv1_bn.beta (64,)
conv2_reduce.W (64, 64, 1, 1)
conv2_reduce_bn.gamma (64,)
conv2_reduce_bn.beta (64,)
conv2.W (192, 64, 3, 3)
conv2_bn.gamma (192,)
conv2_bn.beta (192,)
inception_3a_1x1.W (64, 192, 1, 1)
inception_3a_1x1_bn.gamma (64,)
inception_3a_1x1_bn.beta (64,)
inception_3a_3x3_reduce.W (96, 192, 1, 1)
inception_3a_3x3_reduce_bn.gamma (96,)
inception_3a_3x3_reduce_bn.beta (96,)
inception_3a_3x3.W (128, 96, 3, 3)
inception_3a_3x3_bn.gamma (128,)
inception_3a_3x3_bn.beta (128,)
inception_3a_5x5_reduce.W (16, 192, 1, 1)
inception_3a_5x5_reduce_bn.gamma (16,)
inception_3a_5x5_reduce_bn.beta (16,)
inception_3a_5x5.W (32, 16, 5, 5)
inception_3a_5x5_bn.gamma (32,)
inception_3a_5x5_bn.beta (32,)
inception_3a_pool_proj.W (32, 192, 1, 1)
inception_3a_pool_proj_bn.gamma (32,)
inception_3a_pool_proj_bn.beta (32,)
inception_3b_1x1.W (128, 256, 1, 1)
inception_3b_1x1_bn.gamma (128,)
inception_3b_1x1_bn.beta (128,)
inception_3b_3x3_reduce.W (128, 256, 1, 1)
inception_3b_3x3_reduce_bn.gamma (128,)
inception_3b_3x3_reduce_bn.beta (128,)
inception_3b_3x3.W (192, 128, 3, 3)
inception_3b_3x3_bn.gamma (192,)
inception_3b_3x3_bn.beta (192,)
inception_3b_5x5_reduce.W (32, 256, 1, 1)
inception_3b_5x5_reduce_bn.gamma (32,)
inception_3b_5x5_reduce_bn.beta (32,)
inception_3b_5x5.W (96, 32, 5, 5)
inception_3b_5x5_bn.gamma (96,)
inception_3b_5x5_bn.beta (96,)
inception_3b_pool_proj.W (64, 256, 1, 1)
inception_3b_pool_proj_bn.gamma (64,)
inception_3b_pool_proj_bn.beta (64,)
inception_4a_1x1.W (192, 480, 1, 1)
inception_4a_1x1_bn.gamma (192,)
inception_4a_1x1_bn.beta (192,)
inception_4a_3x3_reduce.W (96, 480, 1, 1)
inception_4a_3x3_reduce_bn.gamma (96,)
inception_4a_3x3_reduce_bn.beta (96,)
inception_4a_3x3.W (208, 96, 3, 3)
inception_4a_3x3_bn.gamma (208,)
inception_4a_3x3_bn.beta (208,)
inception_4a_5x5_reduce.W (16, 480, 1, 1)
inception_4a_5x5_reduce_bn.gamma (16,)
inception_4a_5x5_reduce_bn.beta (16,)
inception_4a_5x5.W (48, 16, 5, 5)
inception_4a_5x5_bn.gamma (48,)
inception_4a_5x5_bn.beta (48,)
inception_4a_pool_proj.W (64, 480, 1, 1)
inception_4a_pool_proj_bn.gamma (64,)
inception_4a_pool_proj_bn.beta (64,)
loss1_conv.W (128, 512, 1, 1)
loss1_conv_bn.gamma (128,)
loss1_conv_bn.beta (128,)
loss1_fc.W (2048, 1024)
loss1_fc_bn.gamma (1024,)
loss1_fc_bn.beta (1024,)
loss1_classifier.W (1024, 1000)
loss1_classifier.b (1000,)
inception_4b_1x1.W (160, 512, 1, 1)
inception_4b_1x1_bn.gamma (160,)
inception_4b_1x1_bn.beta (160,)
inception_4b_3x3_reduce.W (112, 512, 1, 1)
inception_4b_3x3_reduce_bn.gamma (112,)
inception_4b_3x3_reduce_bn.beta (112,)
inception_4b_3x3.W (224, 112, 3, 3)
inception_4b_3x3_bn.gamma (224,)
inception_4b_3x3_bn.beta (224,)
inception_4b_5x5_reduce.W (24, 512, 1, 1)
inception_4b_5x5_reduce_bn.gamma (24,)
inception_4b_5x5_reduce_bn.beta (24,)
inception_4b_5x5.W (64, 24, 5, 5)
inception_4b_5x5_bn.gamma (64,)
inception_4b_5x5_bn.beta (64,)
inception_4b_pool_proj.W (64, 512, 1, 1)
inception_4b_pool_proj_bn.gamma (64,)
inception_4b_pool_proj_bn.beta (64,)
inception_4c_1x1.W (128, 512, 1, 1)
inception_4c_1x1_bn.gamma (128,)
inception_4c_1x1_bn.beta (128,)
inception_4c_3x3_reduce.W (128, 512, 1, 1)
inception_4c_3x3_reduce_bn.gamma (128,)
inception_4c_3x3_reduce_bn.beta (128,)
inception_4c_3x3.W (256, 128, 3, 3)
inception_4c_3x3_bn.gamma (256,)
inception_4c_3x3_bn.beta (256,)
inception_4c_5x5_reduce.W (24, 512, 1, 1)
inception_4c_5x5_reduce_bn.gamma (24,)
inception_4c_5x5_reduce_bn.beta (24,)
inception_4c_5x5.W (64, 24, 5, 5)
inception_4c_5x5_bn.gamma (64,)
inception_4c_5x5_bn.beta (64,)
inception_4c_pool_proj.W (64, 512, 1, 1)
inception_4c_pool_proj_bn.gamma (64,)
inception_4c_pool_proj_bn.beta (64,)
inception_4d_1x1.W (128, 512, 1, 1)
inception_4d_1x1_bn.gamma (128,)
inception_4d_1x1_bn.beta (128,)
inception_4d_3x3_reduce.W (128, 512, 1, 1)
inception_4d_3x3_reduce_bn.gamma (128,)
inception_4d_3x3_reduce_bn.beta (128,)
inception_4d_3x3.W (256, 128, 3, 3)
inception_4d_3x3_bn.gamma (256,)
inception_4d_3x3_bn.beta (256,)
inception_4d_5x5_reduce.W (24, 512, 1, 1)
inception_4d_5x5_reduce_bn.gamma (24,)
inception_4d_5x5_reduce_bn.beta (24,)
inception_4d_5x5.W (64, 24, 5, 5)
inception_4d_5x5_bn.gamma (64,)
inception_4d_5x5_bn.beta (64,)
inception_4d_pool_proj.W (64, 512, 1, 1)
inception_4d_pool_proj_bn.gamma (64,)
inception_4d_pool_proj_bn.beta (64,)
loss2_conv.W (128, 512, 1, 1)
loss2_conv_bn.gamma (128,)
loss2_conv_bn.beta (128,)
loss2_fc.W (2048, 1024)
loss2_fc_bn.gamma (1024,)
loss2_fc_bn.beta (1024,)
loss2_classifier.W (1024, 1000)
loss2_classifier.b (1000,)
inception_4e_1x1.W (256, 512, 1, 1)
inception_4e_1x1_bn.gamma (256,)
inception_4e_1x1_bn.beta (256,)
inception_4e_3x3_reduce.W (160, 512, 1, 1)
inception_4e_3x3_reduce_bn.gamma (160,)
inception_4e_3x3_reduce_bn.beta (160,)
inception_4e_3x3.W (320, 160, 3, 3)
inception_4e_3x3_bn.gamma (320,)
inception_4e_3x3_bn.beta (320,)
inception_4e_5x5_reduce.W (32, 512, 1, 1)
inception_4e_5x5_reduce_bn.gamma (32,)
inception_4e_5x5_reduce_bn.beta (32,)
inception_4e_5x5.W (128, 32, 5, 5)
inception_4e_5x5_bn.gamma (128,)
inception_4e_5x5_bn.beta (128,)
inception_4e_pool_proj.W (128, 512, 1, 1)
inception_4e_pool_proj_bn.gamma (128,)
inception_4e_pool_proj_bn.beta (128,)
inception_5a_1x1.W (256, 832, 1, 1)
inception_5a_1x1_bn.gamma (256,)
inception_5a_1x1_bn.beta (256,)
inception_5a_3x3_reduce.W (160, 832, 1, 1)
inception_5a_3x3_reduce_bn.gamma (160,)
inception_5a_3x3_reduce_bn.beta (160,)
inception_5a_3x3.W (320, 160, 3, 3)
inception_5a_3x3_bn.gamma (320,)
inception_5a_3x3_bn.beta (320,)
inception_5a_5x5_reduce.W (32, 832, 1, 1)
inception_5a_5x5_reduce_bn.gamma (32,)
inception_5a_5x5_reduce_bn.beta (32,)
inception_5a_5x5.W (128, 32, 5, 5)
inception_5a_5x5_bn.gamma (128,)
inception_5a_5x5_bn.beta (128,)
inception_5a_pool_proj.W (128, 832, 1, 1)
inception_5a_pool_proj_bn.gamma (128,)
inception_5a_pool_proj_bn.beta (128,)
inception_5b_1x1.W (384, 832, 1, 1)
inception_5b_1x1_bn.gamma (384,)
inception_5b_1x1_bn.beta (384,)
inception_5b_3x3_reduce.W (192, 832, 1, 1)
inception_5b_3x3_reduce_bn.gamma (192,)
inception_5b_3x3_reduce_bn.beta (192,)
inception_5b_3x3.W (384, 192, 3, 3)
inception_5b_3x3_bn.gamma (384,)
inception_5b_3x3_bn.beta (384,)
inception_5b_5x5_reduce.W (48, 832, 1, 1)
inception_5b_5x5_reduce_bn.gamma (48,)
inception_5b_5x5_reduce_bn.beta (48,)
inception_5b_5x5.W (128, 48, 5, 5)
inception_5b_5x5_bn.gamma (128,)
inception_5b_5x5_bn.beta (128,)
inception_5b_pool_proj.W (128, 832, 1, 1)
inception_5b_pool_proj_bn.gamma (128,)
inception_5b_pool_proj_bn.beta (128,)
loss3_classifier.W (1024, 1000)
loss3_classifier.b (1000,)
Compiling funtions...
433.708 sec
Starting training...
Iter: 4, train_loss=11.317356    (1.672 sec)
Epoch: 1, train_loss=11.281236, valid_loss=11.191591
Iter: 8, train_loss=11.106550    (1.687 sec)
Epoch: 2, train_loss=11.055969, valid_loss=10.872163
Iter: 12, train_loss=10.498262    (1.687 sec)
Epoch: 3, train_loss=10.511806, valid_loss=10.546569
Iter: 16, train_loss=9.904503    (1.757 sec)
Epoch: 4, train_loss=9.775131, valid_loss=10.176313
Iter: 20, train_loss=8.921951    (1.794 sec)
Epoch: 5, train_loss=8.902020, valid_loss=9.811245
Iter: 24, train_loss=8.007676    (1.780 sec)
Epoch: 6, train_loss=7.834020, valid_loss=9.522657
Iter: 28, train_loss=6.810879    (1.873 sec)
Epoch: 7, train_loss=6.654216, valid_loss=9.297453
Iter: 32, train_loss=5.678864    (1.866 sec)
Epoch: 8, train_loss=5.513952, valid_loss=9.143353
Iter: 36, train_loss=4.600856    (1.869 sec)
Epoch: 9, train_loss=4.439848, valid_loss=8.973049
Iter: 40, train_loss=3.636676    (1.849 sec)
Epoch: 10, train_loss=3.526212, valid_loss=8.867658
Iter: 44, train_loss=2.792329    (1.821 sec)
Epoch: 11, train_loss=2.785167, valid_loss=8.777158
Iter: 48, train_loss=2.171124    (1.825 sec)
Epoch: 12, train_loss=2.121032, valid_loss=8.709158
Iter: 52, train_loss=1.497761    (1.832 sec)
Epoch: 13, train_loss=1.516489, valid_loss=8.692670
Iter: 56, train_loss=0.957697    (1.821 sec)
Epoch: 14, train_loss=1.025406, valid_loss=8.659511
Iter: 60, train_loss=0.595756    (1.819 sec)
Epoch: 15, train_loss=0.635963, valid_loss=8.639914
Iter: 64, train_loss=0.357384    (1.810 sec)
Epoch: 16, train_loss=0.381654, valid_loss=8.610470
Iter: 68, train_loss=0.239510    (1.792 sec)
Epoch: 17, train_loss=0.247699, valid_loss=8.622191
Iter: 72, train_loss=0.157777    (1.795 sec)
Epoch: 18, train_loss=0.166918, valid_loss=8.597554
Iter: 76, train_loss=0.114707    (1.800 sec)
Epoch: 19, train_loss=0.121977, valid_loss=8.585332
Iter: 80, train_loss=0.081443    (1.801 sec)
Epoch: 20, train_loss=0.094056, valid_loss=8.590514
Iter: 84, train_loss=0.071740    (1.792 sec)
Epoch: 21, train_loss=0.074530, valid_loss=8.594355
Iter: 88, train_loss=0.055834    (1.797 sec)
Epoch: 22, train_loss=0.061788, valid_loss=8.572407
Iter: 92, train_loss=0.051669    (1.804 sec)
Epoch: 23, train_loss=0.051987, valid_loss=8.587033
Iter: 96, train_loss=0.048234    (1.792 sec)
Epoch: 24, train_loss=0.046064, valid_loss=8.562992
Iter: 100, train_loss=0.039240    (1.815 sec)
Epoch: 25, train_loss=0.041277, valid_loss=8.568976
Iter: 104, train_loss=0.034677    (1.818 sec)
Epoch: 26, train_loss=0.037225, valid_loss=8.567257
Iter: 108, train_loss=0.034471    (1.841 sec)
Epoch: 27, train_loss=0.034478, valid_loss=8.595433
Iter: 112, train_loss=0.032977    (1.844 sec)
Epoch: 28, train_loss=0.033177, valid_loss=8.566539
Iter: 116, train_loss=0.030428    (1.847 sec)
Epoch: 29, train_loss=0.030408, valid_loss=8.571244
Iter: 120, train_loss=0.028012    (1.843 sec)
Epoch: 30, train_loss=0.028770, valid_loss=8.576855
Iter: 124, train_loss=0.026552    (1.838 sec)
Epoch: 31, train_loss=0.028068, valid_loss=8.570888
Iter: 128, train_loss=0.024770    (1.845 sec)
Epoch: 32, train_loss=0.026061, valid_loss=8.559755
Iter: 132, train_loss=0.025236    (1.823 sec)
Epoch: 33, train_loss=0.025393, valid_loss=8.574043
Iter: 136, train_loss=0.023321    (1.792 sec)
Epoch: 34, train_loss=0.024542, valid_loss=8.569159
Iter: 140, train_loss=0.024014    (1.798 sec)
Epoch: 35, train_loss=0.023955, valid_loss=8.573041
Iter: 144, train_loss=0.024097    (1.794 sec)
Epoch: 36, train_loss=0.023227, valid_loss=8.575433
Iter: 148, train_loss=0.022434    (1.802 sec)
Epoch: 37, train_loss=0.022750, valid_loss=8.558123
Iter: 152, train_loss=0.020805    (1.803 sec)
Epoch: 38, train_loss=0.021647, valid_loss=8.557933
Iter: 156, train_loss=0.019795    (1.794 sec)
Epoch: 39, train_loss=0.021161, valid_loss=8.549715
Iter: 160, train_loss=0.021944    (1.797 sec)
Epoch: 40, train_loss=0.020387, valid_loss=8.573393
Iter: 164, train_loss=0.019712    (1.796 sec)
Epoch: 41, train_loss=0.020195, valid_loss=8.560852
Iter: 168, train_loss=0.019113    (1.795 sec)
Epoch: 42, train_loss=0.019770, valid_loss=8.568389
Iter: 172, train_loss=0.019382    (1.798 sec)
Epoch: 43, train_loss=0.019572, valid_loss=8.573833
Iter: 176, train_loss=0.018761    (1.826 sec)
Epoch: 44, train_loss=0.019023, valid_loss=8.555466
Iter: 180, train_loss=0.019892    (1.814 sec)
Epoch: 45, train_loss=0.018363, valid_loss=8.560494
Iter: 184, train_loss=0.016057    (1.823 sec)
Epoch: 46, train_loss=0.017344, valid_loss=8.551167
Iter: 188, train_loss=0.017790    (1.819 sec)
Epoch: 47, train_loss=0.017764, valid_loss=8.568426
Iter: 192, train_loss=0.017404    (1.818 sec)
Epoch: 48, train_loss=0.016663, valid_loss=8.560171
Iter: 196, train_loss=0.017309    (1.821 sec)
Epoch: 49, train_loss=0.016841, valid_loss=8.573752
Iter: 200, train_loss=0.014965    (1.821 sec)
Epoch: 50, train_loss=0.016949, valid_loss=8.566319
Iter: 204, train_loss=0.015602    (1.816 sec)
Epoch: 51, train_loss=0.015550, valid_loss=8.551330
Iter: 208, train_loss=0.014300    (1.815 sec)
Epoch: 52, train_loss=0.016374, valid_loss=8.568254
Iter: 212, train_loss=0.013896    (1.814 sec)
Epoch: 53, train_loss=0.015052, valid_loss=8.569056
Iter: 216, train_loss=0.013656    (1.835 sec)
Epoch: 54, train_loss=0.014701, valid_loss=8.551335
Iter: 220, train_loss=0.014055    (1.817 sec)
Epoch: 55, train_loss=0.014782, valid_loss=8.549664
Iter: 224, train_loss=0.013189    (1.814 sec)
Epoch: 56, train_loss=0.014466, valid_loss=8.557901
Iter: 228, train_loss=0.013733    (1.826 sec)
Epoch: 57, train_loss=0.014716, valid_loss=8.551003
Iter: 232, train_loss=0.013663    (1.822 sec)
Epoch: 58, train_loss=0.014413, valid_loss=8.550224
Iter: 236, train_loss=0.013407    (1.818 sec)
Epoch: 59, train_loss=0.013887, valid_loss=8.560308
Iter: 240, train_loss=0.014713    (1.820 sec)
Epoch: 60, train_loss=0.013932, valid_loss=8.548925
Iter: 244, train_loss=0.013412    (1.817 sec)
Epoch: 61, train_loss=0.013262, valid_loss=8.540100
Iter: 248, train_loss=0.012272    (1.822 sec)
Epoch: 62, train_loss=0.013341, valid_loss=8.543515
Iter: 252, train_loss=0.012858    (1.821 sec)
Epoch: 63, train_loss=0.012791, valid_loss=8.555719
Iter: 256, train_loss=0.013447    (1.820 sec)
Epoch: 64, train_loss=0.012756, valid_loss=8.575732
Iter: 260, train_loss=0.013791    (1.816 sec)
Epoch: 65, train_loss=0.012645, valid_loss=8.543196
Iter: 264, train_loss=0.011995    (1.817 sec)
Epoch: 66, train_loss=0.012035, valid_loss=8.561249
Iter: 268, train_loss=0.012778    (1.827 sec)
Epoch: 67, train_loss=0.012037, valid_loss=8.566212
Iter: 272, train_loss=0.012103    (1.824 sec)
Epoch: 68, train_loss=0.011938, valid_loss=8.572651
Iter: 276, train_loss=0.011167    (1.823 sec)
Epoch: 69, train_loss=0.011893, valid_loss=8.545280
Iter: 280, train_loss=0.011486    (1.815 sec)
Epoch: 70, train_loss=0.011954, valid_loss=8.563585
Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 1.339912e-04s
  Time in Function.fn.__call__: 1.239777e-04s (92.527%)
  Time in thunks: 1.211166e-04s (90.391%)
  Total compile time: 7.110381e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.936934e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.218081e-03s
       Import time 1.819134e-04s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.21e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.21e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.21e-04s      1     0   DeepCopyOp(conv1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.987022e-05s (88.624%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.821012e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.756927e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(conv1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.798%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.799006e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.727840e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.808540e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(conv1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.796288e-05s (84.715%)
  Total compile time: 6.829810e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.881144e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.017094e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(conv2_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.820129e-05s (87.936%)
  Time in thunks: 7.581711e-05s (85.255%)
  Total compile time: 6.795597e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.740000e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.011848e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.58e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.58e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.58e-05s      1     0   DeepCopyOp(conv2_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.947%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.771016e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.727125e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.034975e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(conv2_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.319813e-04s
  Time in Function.fn.__call__: 2.210140e-04s (95.272%)
  Time in thunks: 2.169609e-04s (93.525%)
  Total compile time: 6.825089e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.885197e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.17e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.17e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.17e-04s      1     0   DeepCopyOp(conv2.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.082390e-05s (88.743%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.768489e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.763842e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(conv2_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.987022e-05s (88.624%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.777906e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.795074e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.927750e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(conv2_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.916855e-05s
  Time in Function.fn.__call__: 7.796288e-05s (87.433%)
  Time in thunks: 7.605553e-05s (85.294%)
  Total compile time: 6.788111e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.899979e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.849072e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_3a_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.566%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.771302e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.792929e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.608269e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3a_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.010864e-05s (87.958%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.901813e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.714012e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_3a_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.702278e-05s
  Time in Function.fn.__call__: 7.700920e-05s (88.493%)
  Time in thunks: 7.390976e-05s (84.932%)
  Total compile time: 6.838799e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.844904e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.880066e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.39e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.39e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.39e-05s      1     0   DeepCopyOp(inception_3a_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.179115e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.351%)
  Time in thunks: 7.796288e-05s (84.935%)
  Total compile time: 6.818795e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.002975e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.911060e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_3a_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.179115e-05s
  Time in Function.fn.__call__: 8.106232e-05s (88.312%)
  Time in thunks: 7.677078e-05s (83.636%)
  Total compile time: 7.040596e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.928112e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.68e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.68e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.68e-05s      1     0   DeepCopyOp(inception_3a_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.357960e-04s
  Time in Function.fn.__call__: 2.241135e-04s (95.046%)
  Time in thunks: 2.210140e-04s (93.731%)
  Total compile time: 7.059503e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.124092e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.21e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.21e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.21e-04s      1     0   DeepCopyOp(inception_3a_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 7.796288e-05s (83.846%)
  Total compile time: 7.051182e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.956007e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.000881e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_3a_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.010864e-05s (89.125%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 7.031202e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.946947e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.000166e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3a_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.083748e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.239%)
  Time in thunks: 7.700920e-05s (84.777%)
  Total compile time: 7.051587e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.064964e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.000881e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3a_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 7.987022e-05s (85.897%)
  Total compile time: 7.066393e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.952908e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.858608e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.99e-05s      1     0   DeepCopyOp(inception_3a_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.296967e-05s (90.155%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 7.022619e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.954100e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.013041e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_3a_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 7.915497e-05s (86.911%)
  Time in thunks: 7.605553e-05s (83.508%)
  Total compile time: 7.054090e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.048037e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_3a_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.296967e-05s (90.155%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 7.012296e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.814148e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.880066e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_3a_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.083748e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.239%)
  Time in thunks: 7.796288e-05s (85.827%)
  Total compile time: 6.787801e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.781961e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.958744e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_3a_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 7.987022e-05s (87.696%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.836605e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.892111e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_3a_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.010864e-05s (89.125%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.818819e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.740953e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.870529e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3a_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.987022e-05s (88.624%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.802011e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.729033e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3a_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.429485e-04s
  Time in Function.fn.__call__: 2.329350e-04s (95.878%)
  Time in thunks: 2.291203e-04s (94.308%)
  Total compile time: 6.833315e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.840851e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.29e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.29e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.29e-04s      1     0   DeepCopyOp(inception_3b_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.296967e-05s (90.155%)
  Time in thunks: 8.010864e-05s (87.047%)
  Total compile time: 6.817508e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.710913e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.002073e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.01e-05s      1     0   DeepCopyOp(inception_3b_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 8.082390e-05s (89.683%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.772304e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.788876e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.839535e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3b_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.279282e-04s
  Time in Function.fn.__call__: 2.160072e-04s (94.770%)
  Time in thunks: 2.119541e-04s (92.992%)
  Total compile time: 6.813622e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.851103e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.009941e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.12e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.12e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.12e-04s      1     0   DeepCopyOp(inception_3b_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.010864e-05s (87.958%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.812000e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.821777e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.020193e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_3b_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.891655e-05s (89.702%)
  Time in thunks: 7.510185e-05s (85.366%)
  Total compile time: 6.787992e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.788876e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.438992e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_3b_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.410412e-04s
  Time in Function.fn.__call__: 2.300739e-04s (95.450%)
  Time in thunks: 2.269745e-04s (94.164%)
  Total compile time: 6.777382e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.923820e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.951591e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.27e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.27e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.27e-04s      1     0   DeepCopyOp(inception_3b_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 8.010864e-05s (86.154%)
  Total compile time: 6.782007e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.734039e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.01e-05s      1     0   DeepCopyOp(inception_3b_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.796288e-05s (88.618%)
  Time in thunks: 7.486343e-05s (85.095%)
  Total compile time: 6.766701e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.740000e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.789467e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.49e-05s      1     0   DeepCopyOp(inception_3b_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 7.891655e-05s (84.872%)
  Total compile time: 6.774497e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.828215e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_3b_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 7.987022e-05s (85.897%)
  Total compile time: 6.802607e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.724979e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.920597e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.99e-05s      1     0   DeepCopyOp(inception_3b_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.083748e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.239%)
  Time in thunks: 7.915497e-05s (87.139%)
  Total compile time: 6.766891e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.740953e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.829998e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.92e-05s      1     0   DeepCopyOp(inception_3b_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.678436e-05s
  Time in Function.fn.__call__: 7.605553e-05s (87.637%)
  Time in thunks: 7.414818e-05s (85.440%)
  Total compile time: 6.795692e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.921913e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.620190e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.41e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.41e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.41e-05s      1     0   DeepCopyOp(inception_3b_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.891655e-05s (89.702%)
  Time in thunks: 7.510185e-05s (85.366%)
  Total compile time: 6.901503e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.792929e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_3b_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.106232e-05s (90.186%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.768394e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.729033e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.920597e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3b_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 7.915497e-05s (88.064%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.797123e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.889011e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.829998e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_3b_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.083748e-05s
  Time in Function.fn.__call__: 8.010864e-05s (88.189%)
  Time in thunks: 7.820129e-05s (86.089%)
  Total compile time: 6.786489e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.746914e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.013041e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.82e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.82e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.82e-05s      1     0   DeepCopyOp(inception_3b_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.915497e-05s (89.008%)
  Time in thunks: 7.486343e-05s (84.182%)
  Total compile time: 6.777906e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.776955e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.930134e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.49e-05s      1     0   DeepCopyOp(inception_3b_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.821487e-05s
  Time in Function.fn.__call__: 7.891655e-05s (89.459%)
  Time in thunks: 7.605553e-05s (86.216%)
  Total compile time: 6.789494e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.897833e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4a_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.010864e-05s (89.125%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.791687e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.817009e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.951591e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4a_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.796288e-05s (88.618%)
  Time in thunks: 7.510185e-05s (85.366%)
  Total compile time: 6.791615e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.826069e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_4a_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.288818e-04s
  Time in Function.fn.__call__: 2.169609e-04s (94.792%)
  Time in thunks: 2.129078e-04s (93.021%)
  Total compile time: 6.800294e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.867077e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.023054e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.13e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.13e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.13e-04s      1     0   DeepCopyOp(inception_4a_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.796288e-05s (84.715%)
  Total compile time: 6.798506e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.769087e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4a_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.891655e-05s (88.740%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 6.788516e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.741907e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.002789e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4a_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.520084e-04s
  Time in Function.fn.__call__: 2.398491e-04s (95.175%)
  Time in thunks: 2.360344e-04s (93.661%)
  Total compile time: 6.801200e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.894972e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.36e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.36e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.36e-04s      1     0   DeepCopyOp(inception_4a_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 7.915497e-05s (85.128%)
  Total compile time: 6.825399e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.733086e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.042128e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.92e-05s      1     0   DeepCopyOp(inception_4a_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.821487e-05s
  Time in Function.fn.__call__: 7.796288e-05s (88.378%)
  Time in thunks: 7.510185e-05s (85.135%)
  Total compile time: 6.797886e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.736900e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.033068e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_4a_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.296967e-05s (89.231%)
  Time in thunks: 7.987022e-05s (85.897%)
  Total compile time: 6.837893e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.996777e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.829998e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.99e-05s      1     0   DeepCopyOp(inception_4a_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.005%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.766391e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.770994e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4a_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.179115e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.351%)
  Time in thunks: 7.796288e-05s (84.935%)
  Total compile time: 6.790304e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.817963e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.958744e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4a_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.821487e-05s
  Time in Function.fn.__call__: 7.700920e-05s (87.297%)
  Time in thunks: 7.414818e-05s (84.054%)
  Total compile time: 6.849504e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.873037e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.818077e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.41e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.41e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.41e-05s      1     0   DeepCopyOp(inception_4a_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 6.794715e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.762888e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.927750e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4a_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.083748e-05s
  Time in Function.fn.__call__: 8.201599e-05s (90.289%)
  Time in thunks: 7.915497e-05s (87.139%)
  Total compile time: 6.816888e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.743099e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.92e-05s      1     0   DeepCopyOp(inception_4a_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.566%)
  Time in thunks: 7.510185e-05s (83.333%)
  Total compile time: 6.839204e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.849911e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.839535e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_4a_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.010864e-05s (87.958%)
  Time in thunks: 7.700920e-05s (84.555%)
  Total compile time: 6.806993e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.734993e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.042128e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4a_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.796288e-05s (88.618%)
  Time in thunks: 7.510185e-05s (85.366%)
  Total compile time: 6.785297e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.750967e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.010180e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_4a_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.300739e-04s
  Time in Function.fn.__call__: 2.188683e-04s (95.130%)
  Time in thunks: 2.160072e-04s (93.886%)
  Total compile time: 6.805515e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.860163e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.16e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.16e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.16e-04s      1     0   DeepCopyOp(loss1_conv.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.987022e-05s (88.624%)
  Time in thunks: 7.605553e-05s (84.392%)
  Total compile time: 6.793499e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.776001e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.968281e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(loss1_conv_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.820129e-05s (88.889%)
  Time in thunks: 7.486343e-05s (85.095%)
  Total compile time: 6.790495e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.815817e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.49e-05s      1     0   DeepCopyOp(loss1_conv_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 3.237724e-04s
  Time in Function.fn.__call__: 3.120899e-04s (96.392%)
  Time in thunks: 3.089905e-04s (95.434%)
  Total compile time: 6.799102e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.820824e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.901524e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       3.09e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       3.09e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       3.09e-04s      1     0   DeepCopyOp(loss1_fc.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.894371e-05s
  Time in Function.fn.__call__: 9.012222e-05s (91.084%)
  Time in thunks: 8.606911e-05s (86.988%)
  Total compile time: 6.795907e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.746199e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.849072e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.61e-05s      1     0   DeepCopyOp(loss1_fc_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.177757e-05s (88.860%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 6.801414e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.749060e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.570122e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(loss1_fc_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.768040e-04s
  Time in Function.fn.__call__: 2.660751e-04s (96.124%)
  Time in thunks: 2.629757e-04s (95.004%)
  Total compile time: 6.903601e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.789114e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.951591e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.63e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.63e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.63e-04s      1     0   DeepCopyOp(loss1_classifier.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.512901e-05s
  Time in Function.fn.__call__: 8.583069e-05s (90.226%)
  Time in thunks: 8.296967e-05s (87.218%)
  Total compile time: 6.771994e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.756927e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.003027e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.30e-05s      1     0   DeepCopyOp(loss1_classifier.b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.891655e-05s (89.702%)
  Time in thunks: 7.605553e-05s (86.450%)
  Total compile time: 6.784606e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.838943e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.003027e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4b_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.796288e-05s (88.618%)
  Time in thunks: 7.486343e-05s (85.095%)
  Total compile time: 6.808186e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.770041e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.030922e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.49e-05s      1     0   DeepCopyOp(inception_4b_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.566%)
  Time in thunks: 7.510185e-05s (83.333%)
  Total compile time: 6.798697e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.836082e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.799004e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_4b_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.338886e-04s
  Time in Function.fn.__call__: 2.222061e-04s (95.005%)
  Time in thunks: 2.188683e-04s (93.578%)
  Total compile time: 6.798506e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.933119e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.989738e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.19e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.19e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.19e-04s      1     0   DeepCopyOp(inception_4b_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.082390e-05s (88.743%)
  Time in thunks: 7.891655e-05s (86.649%)
  Total compile time: 6.786895e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.745960e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4b_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.296967e-05s (90.155%)
  Time in thunks: 7.915497e-05s (86.010%)
  Total compile time: 6.803584e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.747868e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.860992e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.92e-05s      1     0   DeepCopyOp(inception_4b_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.391338e-04s
  Time in Function.fn.__call__: 2.269745e-04s (94.915%)
  Time in thunks: 2.231598e-04s (93.320%)
  Total compile time: 6.795907e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.855871e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.999275e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.23e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.23e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.23e-04s      1     0   DeepCopyOp(inception_4b_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 7.891655e-05s (84.872%)
  Total compile time: 6.808019e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.739046e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4b_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.915497e-05s (89.008%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 6.778407e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.747152e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.849072e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4b_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 1.029968e-04s
  Time in Function.fn.__call__: 9.417534e-05s (91.435%)
  Time in thunks: 8.988380e-05s (87.269%)
  Total compile time: 6.798482e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.854918e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.024961e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.99e-05s      1     0   DeepCopyOp(inception_4b_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.010864e-05s (89.125%)
  Time in thunks: 7.677078e-05s (85.411%)
  Total compile time: 6.845093e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.818916e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.003027e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.68e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.68e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.68e-05s      1     0   DeepCopyOp(inception_4b_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.201599e-05s (90.052%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.791210e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.738092e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.007080e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4b_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.310276e-04s
  Time in Function.fn.__call__: 2.210140e-04s (95.666%)
  Time in thunks: 2.169609e-04s (93.911%)
  Total compile time: 6.817794e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.914999e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.048088e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.17e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.17e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.17e-04s      1     0   DeepCopyOp(inception_4b_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.082390e-05s (88.743%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.798196e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.752159e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.920597e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4b_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.987022e-05s (88.624%)
  Time in thunks: 7.605553e-05s (84.392%)
  Total compile time: 6.767488e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.750013e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4b_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.279282e-04s
  Time in Function.fn.__call__: 2.181530e-04s (95.711%)
  Time in thunks: 2.138615e-04s (93.828%)
  Total compile time: 6.806493e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.843950e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.429455e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.14e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.14e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.14e-04s      1     0   DeepCopyOp(inception_4b_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.005%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.782222e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.745007e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4b_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.005%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.790590e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.776955e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.930134e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4b_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.348423e-04s
  Time in Function.fn.__call__: 2.241135e-04s (95.431%)
  Time in thunks: 2.191067e-04s (93.299%)
  Total compile time: 6.831884e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.848003e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.035213e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.19e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.19e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.19e-04s      1     0   DeepCopyOp(inception_4c_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.106232e-05s (88.083%)
  Time in thunks: 7.700920e-05s (83.679%)
  Total compile time: 6.804585e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.785061e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.013994e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4c_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.820129e-05s (87.936%)
  Time in thunks: 7.581711e-05s (85.255%)
  Total compile time: 6.808615e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.757166e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.037121e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.58e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.58e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.58e-05s      1     0   DeepCopyOp(inception_4c_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.350807e-04s
  Time in Function.fn.__call__: 2.229214e-04s (94.828%)
  Time in thunks: 2.200603e-04s (93.611%)
  Total compile time: 6.817102e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.931211e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.720325e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.20e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.20e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.20e-04s      1     0   DeepCopyOp(inception_4c_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.010864e-05s (89.125%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.798196e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.806042e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4c_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.010864e-05s (89.125%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.797099e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.754066e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4c_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.419949e-04s
  Time in Function.fn.__call__: 2.310276e-04s (95.468%)
  Time in thunks: 2.269745e-04s (93.793%)
  Total compile time: 6.812286e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.864216e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.460449e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.27e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.27e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.27e-04s      1     0   DeepCopyOp(inception_4c_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 6.784105e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.736900e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4c_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.700920e-05s (87.534%)
  Time in thunks: 7.510185e-05s (85.366%)
  Total compile time: 6.802297e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.777908e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.570122e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_4c_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.010864e-05s (87.958%)
  Time in thunks: 7.605553e-05s (83.508%)
  Total compile time: 6.910992e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.889965e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.670258e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4c_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 6.776500e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.763842e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.021862e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4c_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.891655e-05s (88.740%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 6.778502e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.795790e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.013994e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4c_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.279282e-04s
  Time in Function.fn.__call__: 2.181530e-04s (95.711%)
  Time in thunks: 2.138615e-04s (93.828%)
  Total compile time: 6.814504e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.914999e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.880066e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.14e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.14e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.14e-04s      1     0   DeepCopyOp(inception_4c_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 6.785107e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.756927e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4c_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.796288e-05s (88.618%)
  Time in thunks: 7.510185e-05s (85.366%)
  Total compile time: 6.783295e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.758120e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.930134e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.51e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.51e-05s      1     0   DeepCopyOp(inception_4c_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.298355e-04s
  Time in Function.fn.__call__: 2.191067e-04s (95.332%)
  Time in thunks: 2.148151e-04s (93.465%)
  Total compile time: 6.822586e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.873037e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.829998e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.15e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.15e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.15e-04s      1     0   DeepCopyOp(inception_4c_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.201599e-05s (90.052%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.786609e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.770994e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.820461e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4c_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.566%)
  Time in thunks: 7.605553e-05s (84.392%)
  Total compile time: 6.797409e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.756927e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.942055e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4c_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.470016e-04s
  Time in Function.fn.__call__: 2.360344e-04s (95.560%)
  Time in thunks: 2.319813e-04s (93.919%)
  Total compile time: 6.800199e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.842997e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.949207e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.32e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.32e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.32e-04s      1     0   DeepCopyOp(inception_4d_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.201599e-05s (90.052%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.791401e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.764080e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.048088e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4d_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.891655e-05s (88.740%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 6.795907e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.744053e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.958744e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4d_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.291203e-04s
  Time in Function.fn.__call__: 2.188683e-04s (95.525%)
  Time in thunks: 2.150536e-04s (93.861%)
  Total compile time: 6.800294e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.840851e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.000166e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.15e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.15e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.15e-04s      1     0   DeepCopyOp(inception_4d_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.296967e-05s (90.155%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 6.796002e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.795074e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.820461e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4d_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.891655e-05s (89.702%)
  Time in thunks: 7.605553e-05s (86.450%)
  Total compile time: 6.796098e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.791975e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4d_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.419949e-04s
  Time in Function.fn.__call__: 2.310276e-04s (95.468%)
  Time in thunks: 2.281666e-04s (94.286%)
  Total compile time: 6.820202e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.873037e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.014948e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.28e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.28e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.28e-04s      1     0   DeepCopyOp(inception_4d_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.082390e-05s (88.743%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.797504e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.740953e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.870529e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4d_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.798%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.789303e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.811049e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.450912e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4d_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.796288e-05s (84.715%)
  Total compile time: 6.822181e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.898787e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.860992e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4d_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.201599e-05s (89.119%)
  Time in thunks: 7.891655e-05s (85.751%)
  Total compile time: 6.798577e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.759073e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.748936e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4d_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.393692e-05s
  Time in Function.fn.__call__: 8.416176e-05s (89.594%)
  Time in thunks: 8.082390e-05s (86.041%)
  Total compile time: 6.807685e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.731894e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.041889e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.08e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.08e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.08e-05s      1     0   DeepCopyOp(inception_4d_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.269745e-04s
  Time in Function.fn.__call__: 2.169609e-04s (95.588%)
  Time in thunks: 2.129078e-04s (93.803%)
  Total compile time: 6.854105e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.852057e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.13e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.13e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.13e-04s      1     0   DeepCopyOp(inception_4d_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.296967e-05s (89.231%)
  Time in thunks: 7.891655e-05s (84.872%)
  Total compile time: 6.803703e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.822016e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.920597e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_4d_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.796288e-05s (87.668%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 6.802702e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.760027e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.961128e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4d_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.279282e-04s
  Time in Function.fn.__call__: 2.181530e-04s (95.711%)
  Time in thunks: 2.138615e-04s (93.828%)
  Total compile time: 6.822920e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.932165e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.860992e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.14e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.14e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.14e-04s      1     0   DeepCopyOp(inception_4d_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.201599e-05s (88.205%)
  Time in thunks: 8.010864e-05s (86.154%)
  Total compile time: 6.795597e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.752159e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.641647e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.01e-05s      1     0   DeepCopyOp(inception_4d_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.566%)
  Time in thunks: 7.605553e-05s (84.392%)
  Total compile time: 6.768703e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.798174e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.908676e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4d_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.450943e-04s
  Time in Function.fn.__call__: 2.219677e-04s (90.564%)
  Time in thunks: 2.181530e-04s (89.008%)
  Total compile time: 6.822801e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.859924e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.999275e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.18e-04s      1     0   DeepCopyOp(loss2_conv.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.947%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.782818e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.716873e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.003981e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(loss2_conv_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.010864e-05s (89.125%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.862807e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.997969e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.720325e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(loss2_conv_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 3.268719e-04s
  Time in Function.fn.__call__: 3.161430e-04s (96.718%)
  Time in thunks: 3.120899e-04s (95.478%)
  Total compile time: 6.856179e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.806995e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       3.12e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       3.12e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       3.12e-04s      1     0   DeepCopyOp(loss2_fc.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.608269e-05s
  Time in Function.fn.__call__: 8.606911e-05s (89.578%)
  Time in thunks: 8.296967e-05s (86.352%)
  Total compile time: 6.783414e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.761934e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.942055e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.30e-05s      1     0   DeepCopyOp(loss2_fc_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.296967e-05s (89.231%)
  Time in thunks: 7.987022e-05s (85.897%)
  Total compile time: 6.824613e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.774809e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.820461e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.99e-05s      1     0   DeepCopyOp(loss2_fc_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.748966e-04s
  Time in Function.fn.__call__: 2.651215e-04s (96.444%)
  Time in thunks: 2.608299e-04s (94.883%)
  Total compile time: 6.795311e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.802942e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.949207e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.61e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.61e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.61e-04s      1     0   DeepCopyOp(loss2_classifier.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.703636e-05s
  Time in Function.fn.__call__: 8.702278e-05s (89.681%)
  Time in thunks: 8.296967e-05s (85.504%)
  Total compile time: 6.814790e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.745960e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.070023e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.30e-05s      1     0   DeepCopyOp(loss2_classifier.b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.338886e-04s
  Time in Function.fn.__call__: 2.222061e-04s (95.005%)
  Time in thunks: 2.188683e-04s (93.578%)
  Total compile time: 6.819201e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.877090e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.889603e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.19e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.19e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.19e-04s      1     0   DeepCopyOp(inception_4e_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.010864e-05s (87.958%)
  Time in thunks: 7.700920e-05s (84.555%)
  Total compile time: 6.795287e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.778862e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.001835e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4e_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.005%)
  Time in thunks: 7.700920e-05s (84.555%)
  Total compile time: 6.801581e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.799843e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.968281e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4e_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.796288e-05s (87.668%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 6.818604e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.877090e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.911060e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4e_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 8.010864e-05s (90.080%)
  Time in thunks: 7.700920e-05s (86.595%)
  Total compile time: 6.787109e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.743099e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.958744e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4e_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 7.915497e-05s (88.064%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.792498e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.777908e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.020193e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4e_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.489090e-04s
  Time in Function.fn.__call__: 2.391338e-04s (96.073%)
  Time in thunks: 2.348423e-04s (94.349%)
  Total compile time: 6.831813e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.832983e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.899139e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.35e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.35e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.35e-04s      1     0   DeepCopyOp(inception_4e_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 1.199245e-04s
  Time in Function.fn.__call__: 1.089573e-04s (90.855%)
  Time in thunks: 1.051426e-04s (87.674%)
  Total compile time: 6.783199e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.801035e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.751320e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.05e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.05e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.05e-04s      1     0   DeepCopyOp(inception_4e_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.417534e-05s
  Time in Function.fn.__call__: 8.392334e-05s (89.114%)
  Time in thunks: 8.010864e-05s (85.063%)
  Total compile time: 6.782198e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.781961e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.024008e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.01e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.01e-05s      1     0   DeepCopyOp(inception_4e_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.082390e-05s (88.743%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.841993e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.841089e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.992123e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_4e_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.296967e-05s (89.231%)
  Time in thunks: 7.987022e-05s (85.897%)
  Total compile time: 6.809187e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.819870e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.99e-05s      1     0   DeepCopyOp(inception_4e_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.083748e-05s
  Time in Function.fn.__call__: 8.010864e-05s (88.189%)
  Time in thunks: 7.820129e-05s (86.089%)
  Total compile time: 6.790781e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.770994e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.889603e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.82e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.82e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.82e-05s      1     0   DeepCopyOp(inception_4e_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.201599e-05s
  Time in Function.fn.__call__: 7.200241e-05s (87.791%)
  Time in thunks: 6.890297e-05s (84.012%)
  Total compile time: 6.829286e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.919052e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.911060e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       6.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       6.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       6.89e-05s      1     0   DeepCopyOp(inception_4e_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.915497e-05s (89.008%)
  Time in thunks: 7.581711e-05s (85.255%)
  Total compile time: 6.794596e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.736900e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.799004e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.58e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.58e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.58e-05s      1     0   DeepCopyOp(inception_4e_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.987022e-05s (88.624%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.780410e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.745960e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.951591e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_4e_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.310276e-04s
  Time in Function.fn.__call__: 2.198219e-04s (95.150%)
  Time in thunks: 2.160072e-04s (93.498%)
  Total compile time: 6.843495e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.837990e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.901524e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.16e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.16e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.16e-04s      1     0   DeepCopyOp(inception_4e_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 1.041889e-04s
  Time in Function.fn.__call__: 9.393692e-05s (90.160%)
  Time in thunks: 9.107590e-05s (87.414%)
  Total compile time: 6.826997e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.782200e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.008034e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       9.11e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       9.11e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       9.11e-05s      1     0   DeepCopyOp(inception_4e_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.987022e-05s (88.624%)
  Time in thunks: 7.605553e-05s (84.392%)
  Total compile time: 6.816006e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.729033e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.005173e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_4e_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.450943e-04s
  Time in Function.fn.__call__: 2.338886e-04s (95.428%)
  Time in thunks: 2.300739e-04s (93.872%)
  Total compile time: 6.806111e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.850864e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.023054e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.30e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.30e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.30e-04s      1     0   DeepCopyOp(inception_5a_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.179115e-05s
  Time in Function.fn.__call__: 8.296967e-05s (90.390%)
  Time in thunks: 7.915497e-05s (86.234%)
  Total compile time: 6.793094e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.779100e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.880066e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.92e-05s      1     0   DeepCopyOp(inception_5a_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.916855e-05s
  Time in Function.fn.__call__: 7.891655e-05s (88.503%)
  Time in thunks: 7.605553e-05s (85.294%)
  Total compile time: 6.792212e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.781961e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.939671e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_5a_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.319813e-04s
  Time in Function.fn.__call__: 2.222061e-04s (95.786%)
  Time in thunks: 2.179146e-04s (93.936%)
  Total compile time: 6.814003e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.956961e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.520054e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.18e-04s      1     0   DeepCopyOp(inception_5a_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.005%)
  Time in thunks: 7.796288e-05s (85.602%)
  Total compile time: 6.829405e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.729033e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.880066e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.80e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.80e-05s      1     0   DeepCopyOp(inception_5a_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.891655e-05s (88.740%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 6.829596e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.804850e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.970665e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_5a_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.470016e-04s
  Time in Function.fn.__call__: 2.372265e-04s (96.042%)
  Time in thunks: 2.338886e-04s (94.691%)
  Total compile time: 6.913900e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.865170e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.008987e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.34e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.34e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.34e-04s      1     0   DeepCopyOp(inception_5a_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.703636e-05s
  Time in Function.fn.__call__: 8.702278e-05s (89.681%)
  Time in thunks: 8.296967e-05s (85.504%)
  Total compile time: 6.893897e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.837036e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.720325e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.30e-05s      1     0   DeepCopyOp(inception_5a_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.296967e-05s (89.231%)
  Time in thunks: 7.915497e-05s (85.128%)
  Total compile time: 7.023692e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.858971e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.791851e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.92e-05s      1     0   DeepCopyOp(inception_5a_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.821487e-05s
  Time in Function.fn.__call__: 7.796288e-05s (88.378%)
  Time in thunks: 7.414818e-05s (84.054%)
  Total compile time: 9.924400e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.997969e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.41e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.41e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.41e-05s      1     0   DeepCopyOp(inception_5a_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.584427e-05s
  Time in Function.fn.__call__: 8.606911e-05s (89.801%)
  Time in thunks: 8.201599e-05s (85.572%)
  Total compile time: 6.955695e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.878998e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.004934e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.20e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.20e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.20e-05s      1     0   DeepCopyOp(inception_5a_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.320808e-05s (89.487%)
  Time in thunks: 7.987022e-05s (85.897%)
  Total compile time: 6.960607e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.867077e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.008987e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.99e-05s      1     0   DeepCopyOp(inception_5a_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.797646e-05s
  Time in Function.fn.__call__: 7.891655e-05s (89.702%)
  Time in thunks: 7.390976e-05s (84.011%)
  Total compile time: 6.995201e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.912138e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.101017e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.39e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.39e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.39e-05s      1     0   DeepCopyOp(inception_5a_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.796288e-05s (87.668%)
  Time in thunks: 7.605553e-05s (85.523%)
  Total compile time: 7.002091e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.016088e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.003027e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_5a_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.107590e-05s
  Time in Function.fn.__call__: 8.082390e-05s (88.743%)
  Time in thunks: 7.700920e-05s (84.555%)
  Total compile time: 7.192707e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.998207e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.007080e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_5a_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.410412e-04s
  Time in Function.fn.__call__: 2.279282e-04s (94.560%)
  Time in thunks: 2.241135e-04s (92.977%)
  Total compile time: 7.213402e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.131006e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.908676e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.24e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.24e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.24e-04s      1     0   DeepCopyOp(inception_5a_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.489059e-05s
  Time in Function.fn.__call__: 8.392334e-05s (88.442%)
  Time in thunks: 8.106232e-05s (85.427%)
  Total compile time: 7.220793e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.056858e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.029015e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.11e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.11e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.11e-05s      1     0   DeepCopyOp(inception_5a_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.893013e-05s
  Time in Function.fn.__call__: 7.915497e-05s (89.008%)
  Time in thunks: 7.486343e-05s (84.182%)
  Total compile time: 7.375216e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.844189e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.620190e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.49e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.49e-05s      1     0   DeepCopyOp(inception_5a_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.470016e-04s
  Time in Function.fn.__call__: 2.369881e-04s (95.946%)
  Time in thunks: 2.331734e-04s (94.402%)
  Total compile time: 6.968188e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.927158e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.044989e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.33e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.33e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.33e-04s      1     0   DeepCopyOp(inception_5b_1x1.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.584427e-05s
  Time in Function.fn.__call__: 8.606911e-05s (89.801%)
  Time in thunks: 8.296967e-05s (86.567%)
  Total compile time: 6.970501e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.813910e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.989738e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.30e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.30e-05s      1     0   DeepCopyOp(inception_5b_1x1_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.298325e-05s
  Time in Function.fn.__call__: 8.320808e-05s (89.487%)
  Time in thunks: 7.891655e-05s (84.872%)
  Total compile time: 6.944513e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.815817e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.056910e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.89e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.89e-05s      1     0   DeepCopyOp(inception_5b_1x1_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.520084e-04s
  Time in Function.fn.__call__: 2.410412e-04s (95.648%)
  Time in thunks: 2.369881e-04s (94.040%)
  Total compile time: 7.143903e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.925013e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.042843e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.37e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.37e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.37e-04s      1     0   DeepCopyOp(inception_5b_3x3_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.012222e-05s
  Time in Function.fn.__call__: 7.891655e-05s (87.566%)
  Time in thunks: 7.700920e-05s (85.450%)
  Total compile time: 6.965399e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.841805e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.003981e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_5b_3x3_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 1.029968e-04s
  Time in Function.fn.__call__: 9.202957e-05s (89.352%)
  Time in thunks: 8.988380e-05s (87.269%)
  Total compile time: 6.949306e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.816055e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.920597e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.99e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.99e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.99e-05s      1     0   DeepCopyOp(inception_5b_3x3_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.601147e-04s
  Time in Function.fn.__call__: 2.479553e-04s (95.325%)
  Time in thunks: 2.450943e-04s (94.225%)
  Total compile time: 6.979203e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.023003e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.003027e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.45e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.45e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.45e-04s      1     0   DeepCopyOp(inception_5b_3x3.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.703636e-05s
  Time in Function.fn.__call__: 8.606911e-05s (88.698%)
  Time in thunks: 8.416176e-05s (86.732%)
  Total compile time: 6.983995e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.812002e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.013041e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.42e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.42e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.42e-05s      1     0   DeepCopyOp(inception_5b_3x3_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.202957e-05s
  Time in Function.fn.__call__: 8.296967e-05s (90.155%)
  Time in thunks: 7.915497e-05s (86.010%)
  Total compile time: 6.960893e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.858017e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.980202e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.92e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.92e-05s      1     0   DeepCopyOp(inception_5b_3x3_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.319813e-04s
  Time in Function.fn.__call__: 2.219677e-04s (95.683%)
  Time in thunks: 2.179146e-04s (93.936%)
  Total compile time: 7.029796e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.947901e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.006126e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.18e-04s      1     0   DeepCopyOp(inception_5b_5x5_reduce.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.393692e-05s
  Time in Function.fn.__call__: 8.416176e-05s (89.594%)
  Time in thunks: 8.082390e-05s (86.041%)
  Total compile time: 6.951714e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.819870e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.012087e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.08e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.08e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.08e-05s      1     0   DeepCopyOp(inception_5b_5x5_reduce_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.608269e-05s
  Time in Function.fn.__call__: 8.487701e-05s (88.337%)
  Time in thunks: 8.106232e-05s (84.367%)
  Total compile time: 6.980610e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.938126e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.008034e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.11e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.11e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.11e-05s      1     0   DeepCopyOp(inception_5b_5x5_reduce_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.381802e-04s
  Time in Function.fn.__call__: 2.269745e-04s (95.295%)
  Time in thunks: 2.231598e-04s (93.694%)
  Total compile time: 6.958795e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.904985e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.011133e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.23e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.23e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.23e-04s      1     0   DeepCopyOp(inception_5b_5x5.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.083748e-05s
  Time in Function.fn.__call__: 8.106232e-05s (89.239%)
  Time in thunks: 7.700920e-05s (84.777%)
  Total compile time: 6.950593e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.888058e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.008034e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_5b_5x5_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.916855e-05s
  Time in Function.fn.__call__: 7.891655e-05s (88.503%)
  Time in thunks: 7.605553e-05s (85.294%)
  Total compile time: 6.949306e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.803896e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.531975e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.61e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.61e-05s      1     0   DeepCopyOp(inception_5b_5x5_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 2.329350e-04s
  Time in Function.fn.__call__: 2.219677e-04s (95.292%)
  Time in thunks: 2.179146e-04s (93.552%)
  Total compile time: 6.982112e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.975080e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.008034e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.18e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.18e-04s      1     0   DeepCopyOp(inception_5b_pool_proj.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 1.151562e-04s
  Time in Function.fn.__call__: 1.039505e-04s (90.269%)
  Time in thunks: 1.010895e-04s (87.785%)
  Total compile time: 6.965113e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.831791e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.689331e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.01e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.01e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.01e-04s      1     0   DeepCopyOp(inception_5b_pool_proj_bn.gamma)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 8.988380e-05s
  Time in Function.fn.__call__: 8.106232e-05s (90.186%)
  Time in thunks: 7.700920e-05s (85.676%)
  Total compile time: 6.975198e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.865170e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.002073e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       7.70e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       7.70e-05s      1     0   DeepCopyOp(inception_5b_pool_proj_bn.beta)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 3.030300e-04s
  Time in Function.fn.__call__: 2.920628e-04s (96.381%)
  Time in thunks: 2.791882e-04s (92.132%)
  Total compile time: 6.959510e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.960060e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.610653e-04s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       2.79e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       2.79e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       2.79e-04s      1     0   DeepCopyOp(loss3_classifier.W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1639
  Time in 1 calls to Function.__call__: 9.489059e-05s
  Time in Function.fn.__call__: 8.606911e-05s (90.704%)
  Time in thunks: 8.082390e-05s (85.176%)
  Total compile time: 6.960392e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 4.849195e-03s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.002073e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       8.08e-05s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       8.08e-05s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       8.08e-05s      1     0   DeepCopyOp(loss3_classifier.b)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1678
  Time in 280 calls to Function.__call__: 5.041857e+02s
  Time in Function.fn.__call__: 5.040231e+02s (99.968%)
  Time in thunks: 4.615375e+02s (91.541%)
  Total compile time: 3.840568e+02s
    Number of Apply nodes: 8708
    Theano Optimizer time: 3.527922e+02s
       Theano validate time: 7.215329e+01s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.363360e+01s
       Import time 6.360078e-02s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  33.5%    33.5%     154.587s       2.13e-04s     C   726320    2594   theano.sandbox.cuda.basic_ops.GpuElemwise
  21.7%    55.2%      99.976s       2.30e-03s     C    43400     155   theano.sandbox.cuda.dnn.GpuDnnConvGradI
  15.6%    70.7%      71.873s       2.16e-03s     C    33320     119   theano.sandbox.cuda.dnn.GpuDnnConvGradW
  11.3%    82.0%      52.067s       1.59e-03s     C    32760     117   theano.sandbox.cuda.dnn.GpuDnnConv
   7.0%    89.0%      32.391s       1.36e-04s     C   237720     849   theano.sandbox.cuda.basic_ops.GpuCAReduce
   3.4%    92.4%      15.519s       1.79e-03s     C     8680      31   theano.sandbox.cuda.dnn.GpuDnnPoolGrad
   2.2%    94.6%      10.277s       1.18e-03s     C     8680      31   theano.sandbox.cuda.dnn.GpuDnnPool
   1.6%    96.2%       7.477s       1.48e-03s     Py    5040      18   theano.sandbox.cuda.basic_ops.GpuSplit
   1.5%    97.8%       7.078s       9.87e-05s     C    71680     256   theano.sandbox.cuda.basic_ops.GpuAllocEmpty
   1.1%    98.9%       5.169s       1.03e-03s     C     5040      18   theano.sandbox.cuda.basic_ops.GpuJoin
   0.4%    99.3%       2.040s       5.74e-05s     C    35560     127   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.2%    99.5%       0.982s       1.17e-03s     C      840       3   theano.sandbox.cuda.nnet.GpuCrossentropySoftmaxArgmax1HotWithBias
   0.1%    99.7%       0.561s       2.86e-04s     C     1960       7   theano.sandbox.cuda.blas.GpuDot22Scalar
   0.1%    99.8%       0.501s       2.23e-04s     C     2240       8   theano.sandbox.cuda.blas.GpuDot22
   0.1%    99.8%       0.300s       8.92e-07s     C   336840    1203   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%    99.9%       0.137s       5.67e-07s     C   240800     860   theano.tensor.elemwise.Elemwise
   0.0%    99.9%       0.126s       7.56e-07s     C   167160     597   theano.compile.ops.Shape_i
   0.0%    99.9%       0.076s       9.47e-07s     C    79800     285   theano.tensor.opt.MakeVector
   0.0%    99.9%       0.072s       3.59e-06s     C    20160      72   theano.tensor.subtensor.IncSubtensor
   0.0%    99.9%       0.068s       5.54e-07s     C   122080     436   theano.sandbox.cuda.basic_ops.GpuContiguous
   ... (remaining 10 Classes account for   0.06%(0.26s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  21.7%    21.7%      99.976s       2.30e-03s     C     43400      155   GpuDnnConvGradI{inplace=True}
  15.6%    37.2%      71.873s       2.16e-03s     C     33320      119   GpuDnnConvGradW{inplace=True}
  11.3%    48.5%      52.067s       1.59e-03s     C     32760      117   GpuDnnConv{workmem='small', inplace=True}
   6.1%    54.6%      28.297s       1.42e-04s     C     199360      712   GpuCAReduce{add}{1,0,1,1}
   3.5%    58.1%      16.148s       3.19e-04s     C     50680      181   GpuElemwise{mul,no_inplace}
   3.4%    61.5%      15.519s       1.79e-03s     C     8680       31   GpuDnnPoolGrad
   3.3%    64.8%      15.290s       4.59e-04s     C     33320      119   GpuElemwise{Composite{((i0 * (i1 / i2)) + i3)},no_inplace}
   3.1%    67.9%      14.213s       7.05e-04s     C     20160       72   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2 * i3)) / i4)},no_inplace}
   2.5%    70.4%      11.450s       5.11e-04s     C     22400       80   GpuElemwise{Composite{((i0 * i1 * i2) + (i0 * i1 * i2 * i3))},no_inplace}
   2.2%    72.6%      10.385s       4.88e-04s     C     21280       76   GpuElemwise{true_div,no_inplace}
   2.2%    74.9%      10.277s       1.18e-03s     C     8680       31   GpuDnnPool
   2.2%    77.0%       9.980s       6.04e-04s     C     16520       59   GpuElemwise{Composite{((-(i0 * i1)) / i2)},no_inplace}
   1.9%    78.9%       8.685s       6.20e-04s     C     14000       50   GpuElemwise{Composite{((i0 + i1) + (i2 * i3 * i4))},no_inplace}
   1.7%    80.6%       7.958s       2.54e-04s     C     31360      112   GpuElemwise{sgn,no_inplace}
   1.7%    82.3%       7.668s       3.80e-04s     C     20160       72   GpuElemwise{Composite{(((i0 * i1 * i2) / i3) + ((i0 * i1 * i2 * i4) / i3))},no_inplace}
   1.6%    83.9%       7.477s       1.48e-03s     Py    5040       18   GpuSplit{4}
   1.6%    85.5%       7.271s       3.76e-04s     C     19320       69   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * i2))},no_inplace}
   1.5%    87.0%       7.078s       9.87e-05s     C     71680      256   GpuAllocEmpty
   1.2%    88.3%       5.724s       1.14e-04s     C     50400      180   GpuElemwise{Sub}[(0, 0)]
   1.2%    89.4%       5.313s       2.92e-04s     C     18200       65   GpuElemwise{Composite{((i0 + i1) + (i2 * i3 * i4))}}[(0, 0)]
   ... (remaining 114 Ops account for  10.59%(48.89s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   1.1%     1.1%       4.970s       1.78e-02s    280   8633   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.01}, Constant{0.01})
   1.1%     2.2%       4.967s       1.77e-02s    280   7810   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{1.0})
   1.1%     3.2%       4.947s       1.77e-02s    280   7796   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%     4.1%       4.183s       1.49e-02s    280   5913   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.5}, Constant{1.0})
   0.9%     5.0%       4.174s       1.49e-02s    280   7823   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.5}, Constant{1.0})
   0.9%     5.9%       4.171s       1.49e-02s    280   8646   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.5}, Constant{1.0})
   0.9%     6.8%       4.089s       1.46e-02s    280   8634   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%     7.7%       4.089s       1.46e-02s    280   5863   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%     8.6%       4.088s       1.46e-02s    280   7797   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.8%     9.4%       3.857s       1.38e-02s    280   8705   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{0.01}, Constant{0.01})
   0.8%    10.3%       3.851s       1.38e-02s    280   8703   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{1.0})
   0.8%    11.1%       3.850s       1.37e-02s    280   8020   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.8%    11.9%       3.556s       1.27e-02s    280   1073   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.8%    12.6%       3.552s       1.27e-02s    280   1068   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.8%    13.4%       3.551s       1.27e-02s    280   1078   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%    14.0%       2.614s       9.34e-03s    280   929   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%    14.5%       2.552s       9.12e-03s    280   8347   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.01}, Constant{0.01})
   0.6%    15.1%       2.552s       9.11e-03s    280   7197   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{1.0})
   0.5%    15.6%       2.514s       8.98e-03s    280   7165   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.5%    16.1%       2.290s       8.18e-03s    280   5083   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.5}, Constant{1.0})
   ... (remaining 8688 Apply instances account for 83.88%(387.12s) of the runtime)

Function profiling
==================
  Message: /home/jaehyun/github/lasagne-googlenet/googlenet_bn.py:1697
  Time in 280 calls to Function.__call__: 1.065591e+02s
  Time in Function.fn.__call__: 1.065056e+02s (99.950%)
  Time in thunks: 1.012759e+02s (95.042%)
  Total compile time: 4.894063e+01s
    Number of Apply nodes: 3553
    Theano Optimizer time: 4.172849e+01s
       Theano validate time: 8.036940e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.252129e+00s
       Import time 2.239943e-03s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  51.4%    51.4%      52.030s       1.59e-03s     C    32760     117   theano.sandbox.cuda.dnn.GpuDnnConv
  19.5%    70.8%      19.720s       1.47e-04s     C   134400     480   theano.sandbox.cuda.basic_ops.GpuElemwise
  10.1%    80.9%      10.225s       1.18e-03s     C     8680      31   theano.sandbox.cuda.dnn.GpuDnnPool
   7.2%    88.1%       7.287s       1.08e-04s     C    67480     241   theano.sandbox.cuda.basic_ops.GpuCAReduce
   5.1%    93.2%       5.127s       1.02e-03s     C     5040      18   theano.sandbox.cuda.basic_ops.GpuJoin
   3.3%    96.5%       3.358s       1.02e-04s     C    32760     117   theano.sandbox.cuda.basic_ops.GpuAllocEmpty
   1.7%    98.2%       1.676s       4.83e-05s     C    34720     124   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.9%    99.1%       0.945s       1.13e-03s     C      840       3   theano.sandbox.cuda.nnet.GpuCrossentropySoftmaxArgmax1HotWithBias
   0.3%    99.4%       0.283s       2.02e-04s     C     1400       5   theano.sandbox.cuda.blas.GpuDot22
   0.1%    99.5%       0.136s       6.82e-07s     C   199920     714   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.1%    99.6%       0.092s       7.56e-07s     C   121240     433   theano.compile.ops.Shape_i
   0.1%    99.7%       0.078s       3.98e-05s     C     1960       7   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.1%    99.7%       0.061s       8.52e-07s     C    71400     255   theano.tensor.opt.MakeVector
   0.1%    99.8%       0.055s       5.60e-07s     C    98280     351   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%    99.9%       0.052s       5.30e-07s     C    97720     349   theano.tensor.elemwise.Elemwise
   0.0%    99.9%       0.040s       4.74e-05s     C      840       3   theano.tensor.basic.MaxAndArgmax
   0.0%    99.9%       0.037s       1.15e-06s     C    32200     115   theano.sandbox.cuda.dnn.GpuDnnConvDesc
   0.0%   100.0%       0.035s       4.16e-05s     Py     840       3   theano.sandbox.cuda.basic_ops.GpuFlatten
   0.0%   100.0%       0.024s       5.72e-07s     C    42280     151   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.0%   100.0%       0.013s       1.50e-06s     C     8680      31   theano.sandbox.cuda.dnn.GpuDnnPoolDesc
   ... (remaining 2 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  51.4%    51.4%      52.030s       1.59e-03s     C     32760      117   GpuDnnConv{workmem='small', inplace=True}
  11.1%    62.5%      11.253s       3.38e-04s     C     33320      119   GpuElemwise{Composite{(i0 * (Composite{((i0 * (i1 / i2)) + i3)}(i1, i2, i3, i4) + Abs(Composite{((i0 * (i1 / i2)) + i3)}(i1, i2, i3, i4))))}}[(0, 2)]
  10.1%    72.6%      10.225s       1.18e-03s     C     8680       31   GpuDnnPool
   7.4%    79.9%       7.460s       2.24e-04s     C     33320      119   GpuElemwise{Sub}[(0, 0)]
   5.1%    85.0%       5.127s       1.02e-03s     C     5040       18   GpuJoin
   3.7%    88.7%       3.742s       1.14e-04s     C     32760      117   GpuCAReduce{add}{1,0,1,1}
   3.4%    92.2%       3.492s       1.07e-04s     C     32760      117   GpuCAReduce{pre=sqr,red=add}{1,0,1,1}
   3.3%    95.5%       3.358s       1.02e-04s     C     32760      117   GpuAllocEmpty
   1.7%    97.1%       1.676s       4.83e-05s     C     34720      124   GpuFromHost
   0.9%    98.1%       0.945s       1.13e-03s     C      840        3   GpuCrossentropySoftmaxArgmax1HotWithBias
   0.5%    98.6%       0.537s       1.64e-05s     C     32760      117   GpuElemwise{Composite{(((i0 / i1) / i2) / i3)}}[(0, 0)]
   0.4%    99.0%       0.442s       1.33e-05s     C     33320      119   GpuElemwise{Composite{sqrt((i0 + (i1 * i2)))}}[(0, 2)]
   0.3%    99.3%       0.283s       2.02e-04s     C     1400        5   GpuDot22
   0.1%    99.4%       0.085s       8.59e-07s     C     98560      352   GpuDimShuffle{x,0,x,x}
   0.1%    99.5%       0.078s       3.98e-05s     C     1960        7   HostFromGpu
   0.1%    99.5%       0.063s       8.90e-07s     C     70840      253   Shape_i{0}
   0.1%    99.6%       0.061s       8.52e-07s     C     71400      255   MakeVector
   0.1%    99.6%       0.055s       5.60e-07s     C     98280      351   GpuSubtensor{int64}
   0.0%    99.7%       0.049s       4.96e-07s     C     98280      351   GpuDimShuffle{x,x,x,x}
   0.0%    99.7%       0.040s       4.74e-05s     C      840        3   MaxAndArgmax
   ... (remaining 40 Ops account for   0.27%(0.28s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   3.5%     3.5%       3.549s       1.27e-02s    280   774   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   3.5%     7.0%       3.546s       1.27e-02s    280   778   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   3.5%    10.5%       3.545s       1.27e-02s    280   776   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   2.6%    13.1%       2.609s       9.32e-03s    280   652   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   2.0%    15.1%       1.997s       7.13e-03s    280   1628   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   2.0%    17.0%       1.997s       7.13e-03s    280   1623   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   2.0%    19.0%       1.997s       7.13e-03s    280   1618   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   1.4%    20.4%       1.395s       4.98e-03s    280   3210   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   1.2%    21.6%       1.218s       4.35e-03s    280   696   GpuElemwise{Composite{(i0 * (Composite{((i0 * (i1 / i2)) + i3)}(i1, i2, i3, i4) + Abs(Composite{((i0 * (i1 / i2)) + i3)}(i1, i2, i3, i4))))}}[(0, 2)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuDimShuffle{x,0,x,x}.0, GpuElemwise{Sub}[(0, 0)].0, GpuElemwise{Composite{sqrt((i0 + (i1 * i2)))}}[(0, 2)].0, GpuDimShuffle{x,0,x,x}.0)
   1.0%    22.6%       1.047s       3.74e-03s    280   1204   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   1.0%    23.6%       1.047s       3.74e-03s    280   1199   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   1.0%    24.7%       1.046s       3.74e-03s    280   1194   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   1.0%    25.6%       0.982s       3.51e-03s    280    82   GpuFromHost(input.input)
   0.9%    26.6%       0.945s       3.38e-03s    280   2711   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%    27.5%       0.944s       3.37e-03s    280   1616   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(2, 2), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%    28.4%       0.944s       3.37e-03s    280   2706   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%    29.4%       0.944s       3.37e-03s    280   2998   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%    30.3%       0.944s       3.37e-03s    280   1621   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(2, 2), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%    31.2%       0.943s       3.37e-03s    280   2993   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.9%    32.2%       0.943s       3.37e-03s    280   1626   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(2, 2), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   ... (remaining 3533 Apply instances account for 67.83%(68.69s) of the runtime)

Function profiling
==================
  Message: Sum of all(191) printed profiles at exit excluding Scan op profile.
  Time in 749 calls to Function.__call__: 6.107684e+02s
  Time in Function.fn.__call__: 6.105505e+02s (99.964%)
  Time in thunks: 5.628345e+02s (92.152%)
  Total compile time: 4.468707e+02s
    Number of Apply nodes: 1
    Theano Optimizer time: 3.954335e+02s
       Theano validate time: 8.019023e+01s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.007448e+01s
       Import time 6.602263e-02s

Time in all call to theano.grad() 3.636980e+00s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  31.0%    31.0%     174.307s       2.03e-04s     C   860720    3074   theano.sandbox.cuda.basic_ops.GpuElemwise
  18.5%    49.5%     104.096s       1.59e-03s     C    65520     234   theano.sandbox.cuda.dnn.GpuDnnConv
  17.8%    67.2%      99.976s       2.30e-03s     C    43400     155   theano.sandbox.cuda.dnn.GpuDnnConvGradI
  12.8%    80.0%      71.873s       2.16e-03s     C    33320     119   theano.sandbox.cuda.dnn.GpuDnnConvGradW
   7.0%    87.0%      39.678s       1.30e-04s     C   305200    1090   theano.sandbox.cuda.basic_ops.GpuCAReduce
   3.6%    90.7%      20.502s       1.18e-03s     C    17360      62   theano.sandbox.cuda.dnn.GpuDnnPool
   2.8%    93.4%      15.519s       1.79e-03s     C     8680      31   theano.sandbox.cuda.dnn.GpuDnnPoolGrad
   1.9%    95.3%      10.436s       9.99e-05s     C   104440     373   theano.sandbox.cuda.basic_ops.GpuAllocEmpty
   1.8%    97.1%      10.295s       1.02e-03s     C    10080      36   theano.sandbox.cuda.basic_ops.GpuJoin
   1.3%    98.5%       7.477s       1.48e-03s     Py    5040      18   theano.sandbox.cuda.basic_ops.GpuSplit
   0.7%    99.1%       3.717s       5.29e-05s     C    70280     251   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.3%    99.5%       1.927s       1.15e-03s     C     1680       6   theano.sandbox.cuda.nnet.GpuCrossentropySoftmaxArgmax1HotWithBias
   0.1%    99.6%       0.783s       2.15e-04s     C     3640      13   theano.sandbox.cuda.blas.GpuDot22
   0.1%    99.7%       0.561s       2.86e-04s     C     1960       7   theano.sandbox.cuda.blas.GpuDot22Scalar
   0.1%    99.8%       0.437s       8.14e-07s     C   536760    1917   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%    99.8%       0.218s       7.56e-07s     C   288400    1030   theano.compile.ops.Shape_i
   0.0%    99.8%       0.188s       5.56e-07s     C   338520    1209   theano.tensor.elemwise.Elemwise
   0.0%    99.9%       0.136s       9.02e-07s     C   151200     540   theano.tensor.opt.MakeVector
   0.0%    99.9%       0.113s       5.77e-07s     C   196560     702   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%       0.092s       5.58e-07s     C   164360     587   theano.sandbox.cuda.basic_ops.GpuContiguous
   ... (remaining 13 Classes account for   0.09%(0.50s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  18.5%    18.5%     104.096s       1.59e-03s     C     65520      234   GpuDnnConv{workmem='small', inplace=True}
  17.8%    36.3%      99.976s       2.30e-03s     C     43400      155   GpuDnnConvGradI{inplace=True}
  12.8%    49.0%      71.873s       2.16e-03s     C     33320      119   GpuDnnConvGradW{inplace=True}
   5.7%    54.7%      32.038s       1.38e-04s     C     232120      829   GpuCAReduce{add}{1,0,1,1}
   3.6%    58.4%      20.502s       1.18e-03s     C     17360       62   GpuDnnPool
   2.9%    61.2%      16.148s       3.19e-04s     C     50680      181   GpuElemwise{mul,no_inplace}
   2.8%    64.0%      15.519s       1.79e-03s     C     8680       31   GpuDnnPoolGrad
   2.7%    66.7%      15.290s       4.59e-04s     C     33320      119   GpuElemwise{Composite{((i0 * (i1 / i2)) + i3)},no_inplace}
   2.5%    69.2%      14.213s       7.05e-04s     C     20160       72   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2 * i3)) / i4)},no_inplace}
   2.3%    71.6%      13.184s       1.57e-04s     C     83720      299   GpuElemwise{Sub}[(0, 0)]
   2.0%    73.6%      11.450s       5.11e-04s     C     22400       80   GpuElemwise{Composite{((i0 * i1 * i2) + (i0 * i1 * i2 * i3))},no_inplace}
   2.0%    75.6%      11.253s       3.38e-04s     C     33320      119   GpuElemwise{Composite{(i0 * (Composite{((i0 * (i1 / i2)) + i3)}(i1, i2, i3, i4) + Abs(Composite{((i0 * (i1 / i2)) + i3)}(i1, i2, i3, i4))))}}[(0, 2)]
   1.9%    77.5%      10.436s       9.99e-05s     C     104440      373   GpuAllocEmpty
   1.8%    79.3%      10.385s       4.88e-04s     C     21280       76   GpuElemwise{true_div,no_inplace}
   1.8%    81.1%      10.295s       1.02e-03s     C     10080       36   GpuJoin
   1.8%    82.9%       9.980s       6.04e-04s     C     16520       59   GpuElemwise{Composite{((-(i0 * i1)) / i2)},no_inplace}
   1.5%    84.5%       8.685s       6.20e-04s     C     14000       50   GpuElemwise{Composite{((i0 + i1) + (i2 * i3 * i4))},no_inplace}
   1.4%    85.9%       7.958s       2.54e-04s     C     31360      112   GpuElemwise{sgn,no_inplace}
   1.4%    87.2%       7.668s       3.80e-04s     C     20160       72   GpuElemwise{Composite{(((i0 * i1 * i2) / i3) + ((i0 * i1 * i2 * i4) / i3))},no_inplace}
   1.3%    88.6%       7.477s       1.48e-03s     Py    5040       18   GpuSplit{4}
   ... (remaining 122 Ops account for  11.44%(64.41s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   0.9%     0.9%       4.970s       1.78e-02s    280   8633   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.01}, Constant{0.01})
   0.9%     1.8%       4.967s       1.77e-02s    280   7810   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{1.0})
   0.9%     2.6%       4.947s       1.77e-02s    280   7796   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.7%     3.4%       4.183s       1.49e-02s    280   5913   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.5}, Constant{1.0})
   0.7%     4.1%       4.174s       1.49e-02s    280   7823   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.5}, Constant{1.0})
   0.7%     4.9%       4.171s       1.49e-02s    280   8646   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{0.5}, Constant{1.0})
   0.7%     5.6%       4.089s       1.46e-02s    280   8634   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.7%     6.3%       4.089s       1.46e-02s    280   5863   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.7%     7.0%       4.088s       1.46e-02s    280   7797   GpuDnnConvGradI{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.7%     7.7%       3.857s       1.38e-02s    280   8705   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{0.01}, Constant{0.01})
   0.7%     8.4%       3.851s       1.38e-02s    280   8703   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{1.0})
   0.7%     9.1%       3.850s       1.37e-02s    280   8020   GpuDnnConvGradW{inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%     9.7%       3.556s       1.27e-02s    280   1073   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%    10.4%       3.552s       1.27e-02s    280   1068   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%    11.0%       3.551s       1.27e-02s    280   1078   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%    11.6%       3.549s       1.27e-02s    280   774   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%    12.3%       3.546s       1.27e-02s    280   778   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.6%    12.9%       3.545s       1.27e-02s    280   776   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(1, 1), subsample=(1, 1), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.5%    13.4%       2.614s       9.34e-03s    280   929   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   0.5%    13.8%       2.609s       9.32e-03s    280   652   GpuDnnConv{workmem='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode=(3, 3), subsample=(2, 2), conv_mode='cross'}.0, Constant{1.0}, Constant{0.0})
   ... (remaining 12430 Apply instances account for 86.18%(485.08s) of the runtime)

